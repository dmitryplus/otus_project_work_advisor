# text_query_test.py
# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç—ã —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º langgraph –∏ early stopping
import base64
import os
from typing import TypedDict, Annotated
from langchain_core.prompts import PromptTemplate

from langgraph.graph import StateGraph, END
from src.rag_service import RAGService
from src.llm_service import LLMService
from src.ocr_service import OCRService
from src.prompt_service import PromptService


# --- –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≥—Ä–∞—Ñ–∞ ---
class GraphState(TypedDict):
    query: str
    relevants: list
    context: str
    response: str
    image_data: str
    prompt_template: PromptTemplate


# --- –£–∑–ª—ã –≥—Ä–∞—Ñ–∞ ---
def retrieve_rag_node(state: GraphState) -> dict:
    """–ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é RAG."""
    print("üîç –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")

    if not state["query"]:
        return {"response": "‚ùå –ó–∞–ø—Ä–æ—Å –ø—É—Å—Ç. –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–∏—Å–∫."}

    rag_service = RAGService()
    relevants = rag_service.search_relevant_documents(state["query"], top_k=3)

    if not relevants:
        return {"response": "‚ùå –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."}

    context = rag_service.format_context(relevants)

    return {
        "relevants": relevants,
        "context": context,
    }


def decide_to_generate(state: GraphState) -> str:
    """–†–µ—à–∞–µ—Ç, –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç—å –ª–∏ –∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–ª–∏ –∑–∞–≤–µ—Ä—à–∏—Ç—å –≥—Ä–∞—Ñ."""
    if state["response"]:
        return "end"
    return "generate"


def generate_node(state: GraphState) -> dict:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é LLM –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ '–ü–æ–¥—Ä–æ–±–Ω–µ–µ –≤ –∑–∞–¥–∞—á–∞—Ö'."""
    print("generate_node")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ prompt_template
    if "prompt_template" not in state or state["prompt_template"] is None:
        return {"response": "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —à–∞–±–ª–æ–Ω –∑–∞–ø—Ä–æ—Å–∞."}

    print("üß† –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞...")

    llm_service = LLMService(model="yandexgpt-lite", prompt_template=state["prompt_template"])
    response = llm_service.generate_response(question=state["query"], context=state["context"]).strip()

    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–¥–∞—á–∞—Ö –≤ –æ—Ç–≤–µ—Ç
    full_response = response
    if state["relevants"]:
        full_response += "\n\nüìö –ü–æ–¥—Ä–æ–±–Ω–µ–µ –≤ –∑–∞–¥–∞—á–∞—Ö:\n"
        for doc in state["relevants"]:
            full_response += f"‚Ä¢ {doc['title']}\n"
            full_response += f"  {doc['url']}\n"

    return {"response": full_response}


def ocr_image_node(state: GraphState) -> dict:
    """–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ query."""
    if not state["image_data"]:
        return {}

    print("üñºÔ∏è –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏...")
    ocr_service = OCRService()

    try:
        # –ï—Å–ª–∏ image_data ‚Äî base64
        if state["image_data"].startswith("data:image"):
            # –ò–∑–≤–ª–µ–∫–∞–µ–º base64 —á–∞—Å—Ç—å
            base64_data = state["image_data"].split(",")[1]
        else:
            base64_data = state["image_data"]

        recognized_text = ocr_service.analyze_image(base64_data)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        if not recognized_text or not recognized_text.strip():
            return {"response": "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏."}


        return {"query": recognized_text}

    except Exception as e:
        return {"response": "‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}"}


def route_image_or_query(state: GraphState) -> str:
    """–†–µ—à–∞–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ —Å—Ä–∞–∑—É –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç—å –∫ –ø–æ–∏—Å–∫—É."""
    if state["image_data"]:
        return "ocr"
    return "retrieve"


def init_prompt_template_node(state: GraphState) -> dict:
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è prompt_template, –µ—Å–ª–∏ –æ–Ω –Ω–µ –∑–∞–¥–∞–Ω."""

    template_path = 'prompts/answer_from_documents.txt'

    if state["image_data"]:
        template_path='prompts/text_from_image_to_query.txt'

    prompt_service = PromptService(template_path=template_path)
    prompt_template = prompt_service.get_prompt_template()

    print("üìù –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —à–∞–±–ª–æ–Ω–∞ –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∏...")
    return {"prompt_template": prompt_template}


# --- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞ ---
workflow = StateGraph(GraphState)


workflow.add_node("retrieve", retrieve_rag_node)
workflow.add_node("init_prompt", init_prompt_template_node)
workflow.add_node("generate", generate_node)
workflow.add_node("ocr", ocr_image_node)

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–π —Ä–æ—É—Ç–∏–Ω–≥
workflow.set_conditional_entry_point(
    route_image_or_query,
    {
        "ocr": "ocr",
        "retrieve": "retrieve"
    }
)

# –ü–µ—Ä–µ—Ö–æ–¥ —Å OCR –Ω–∞ retrieve
workflow.add_edge("ocr", "retrieve")

# –£—Å–ª–æ–≤–Ω—ã–π –ø–µ—Ä–µ—Ö–æ–¥ –ø–æ—Å–ª–µ retrieve: –µ—Å–ª–∏ –µ—Å—Ç—å response ‚Äî –∑–∞–≤–µ—Ä—à–∞–µ–º, –∏–Ω–∞—á–µ –∏–¥—ë–º –¥–∞–ª—å—à–µ
workflow.add_conditional_edges(
    "retrieve",
    decide_to_generate,
    {
        "generate": "init_prompt",  # –¢–µ–ø–µ—Ä—å –∏–¥—ë–º —á–µ—Ä–µ–∑ init_prompt
        "end": END
    }
)

# –ü–µ—Ä–µ—Ö–æ–¥ –æ—Ç init_prompt –∫ generate
workflow.add_edge("init_prompt", "generate")

workflow.add_edge("generate", END)

# –°–æ–±–∏—Ä–∞–µ–º –≥—Ä–∞—Ñ
app = workflow.compile()


# --- –ó–∞–ø—É—Å–∫ ---
if __name__ == "__main__":
    query = "–ß—Ç–æ –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å —Å –∞–∫—Å–µ–ª–µ—Ä–∞—Ç–æ—Ä–∞–º–∏?"

    inputs = {
        "query": query,
        "relevants": [],
        "context": "",
        "response": "",
        "image_data": ""
    }

    # image_path = "img/users_count.png"
    #
    # # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª
    # if not os.path.exists(image_path):
    #     raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {image_path}. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø—É—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω.")
    #
    # # –ß—Ç–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ base64
    # with open(image_path, "rb") as image_file:
    #     encoded_image = base64.b64encode(image_file.read()).decode("utf-8")
    #
    # inputs = {
    #     "query": "",
    #     "relevants": [],
    #     "context": "",
    #     "response": "",
    #     "image_data": encoded_image
    # }

    print("üöÄ –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º langgraph...")
    result = app.invoke(inputs)

    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    print("\n" + "=" * 50)
    print("–í–æ–ø—Ä–æ—Å:")
    print(inputs["query"])

    print("\n–û—Ç–≤–µ—Ç:")
    print(result["response"])
    print("=" * 50)